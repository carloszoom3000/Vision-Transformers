{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajo practico 3 de Vision Trasnformers\n",
    "\n",
    "Por Carlos Villalobos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea: Fine-tuning de un modelo Vision Transformer\n",
    "\n",
    "1. **Objetivo**: \n",
    "   Seleccione un modelo preentrenado que utilice Vision Transformers (ViTs) y un conjunto de datos adecuado. Realice un proceso de fine-tuning del modelo seleccionado.\n",
    "\n",
    "   Pueden encontrar la documentacion de Transformers de Hugging Face en [Link](https://huggingface.co/docs/transformers/index)\n",
    "\n",
    "   Datasets de imágenes en Hugging Face [Link](https://huggingface.co/datasets?modality=modality:image&sort=downloads)\n",
    "\n",
    "   O pueden usar fuentes de preferencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-08T23:19:36.237394Z",
     "iopub.status.busy": "2024-11-08T23:19:36.236840Z",
     "iopub.status.idle": "2024-11-08T23:19:49.012799Z",
     "shell.execute_reply": "2024-11-08T23:19:49.011683Z",
     "shell.execute_reply.started": "2024-11-08T23:19:36.237356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision transformers Pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T23:21:43.840226Z",
     "iopub.status.busy": "2024-11-08T23:21:43.839810Z",
     "iopub.status.idle": "2024-11-08T23:21:55.321666Z",
     "shell.execute_reply": "2024-11-08T23:21:55.320390Z",
     "shell.execute_reply.started": "2024-11-08T23:21:43.840183Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T23:22:58.292346Z",
     "iopub.status.busy": "2024-11-08T23:22:58.291328Z",
     "iopub.status.idle": "2024-11-08T23:56:54.717728Z",
     "shell.execute_reply": "2024-11-08T23:56:54.716846Z",
     "shell.execute_reply.started": "2024-11-08T23:22:58.292297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 791918971/791918971 [00:21<00:00, 37066515.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
      "Downloading https://thor.robots.ox.ac.uk/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19173078/19173078 [00:01<00:00, 14073417.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d157ff29e24f411ba3a01bbae87accef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a0f8893d6e4aa9a032df2d049ce78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9d1b7f4ba4499bbbde8474d4c6dec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating pre-trained model (before fine-tuning)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 115/115 [00:50<00:00,  2.28it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained Model Accuracy: 0.0292\n",
      "\n",
      "Detailed Classification Report (Pre-trained):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.28      0.21        98\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.03      0.04      0.03       100\n",
      "           3       0.01      0.06      0.02       100\n",
      "           4       0.00      0.00      0.00       100\n",
      "           5       1.00      0.01      0.02       100\n",
      "           6       0.00      0.00      0.00       100\n",
      "           7       0.06      0.31      0.10        88\n",
      "           8       0.07      0.08      0.08        99\n",
      "           9       0.02      0.07      0.03       100\n",
      "          10       0.05      0.03      0.04       100\n",
      "          11       0.00      0.00      0.00        97\n",
      "          12       0.00      0.00      0.00       100\n",
      "          13       0.00      0.00      0.00       100\n",
      "          14       0.14      0.17      0.16       100\n",
      "          15       0.00      0.00      0.00       100\n",
      "          16       0.02      0.02      0.02       100\n",
      "          17       0.00      0.00      0.00       100\n",
      "          18       0.00      0.00      0.00        99\n",
      "          19       0.01      0.01      0.01       100\n",
      "          20       0.00      0.00      0.00       100\n",
      "          21       0.00      0.00      0.00       100\n",
      "          22       0.00      0.00      0.00       100\n",
      "          23       0.00      0.00      0.00       100\n",
      "          24       0.01      0.01      0.01       100\n",
      "          25       0.07      0.03      0.04       100\n",
      "          26       0.00      0.00      0.00       100\n",
      "          27       0.00      0.00      0.00       100\n",
      "          28       0.00      0.00      0.00       100\n",
      "          29       0.00      0.00      0.00       100\n",
      "          30       0.00      0.00      0.00        99\n",
      "          31       0.00      0.00      0.00       100\n",
      "          32       0.00      0.00      0.00       100\n",
      "          33       0.00      0.00      0.00       100\n",
      "          34       0.00      0.00      0.00        89\n",
      "          35       0.00      0.00      0.00       100\n",
      "          36       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.03      3669\n",
      "   macro avg       0.05      0.03      0.02      3669\n",
      "weighted avg       0.05      0.03      0.02      3669\n",
      "\n",
      "\n",
      "Starting fine-tuning process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 115/115 [02:03<00:00,  1.08s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:52<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Average Training Loss: 1.5853\n",
      "Test Accuracy: 0.8842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 115/115 [02:12<00:00,  1.15s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:53<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Average Training Loss: 0.2195\n",
      "Test Accuracy: 0.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 115/115 [02:13<00:00,  1.16s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:54<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Average Training Loss: 0.0617\n",
      "Test Accuracy: 0.9147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 115/115 [02:14<00:00,  1.17s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:54<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Average Training Loss: 0.0255\n",
      "Test Accuracy: 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 115/115 [02:13<00:00,  1.16s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:53<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Average Training Loss: 0.0123\n",
      "Test Accuracy: 0.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 115/115 [02:14<00:00,  1.17s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:54<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Average Training Loss: 0.0079\n",
      "Test Accuracy: 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 115/115 [02:14<00:00,  1.17s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:53<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Average Training Loss: 0.0057\n",
      "Test Accuracy: 0.9210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 115/115 [02:14<00:00,  1.17s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:54<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Average Training Loss: 0.0044\n",
      "Test Accuracy: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 115/115 [02:13<00:00,  1.16s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:53<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Average Training Loss: 0.0035\n",
      "Test Accuracy: 0.9220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 115/115 [02:13<00:00,  1.16s/it]\n",
      "Evaluating: 100%|██████████| 115/115 [00:53<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Average Training Loss: 0.0028\n",
      "Test Accuracy: 0.9220\n",
      "\n",
      "Evaluating fine-tuned model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 115/115 [00:53<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model Accuracy: 0.9220\n",
      "\n",
      "Detailed Classification Report (Fine-tuned):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94        98\n",
      "           1       0.77      0.89      0.83       100\n",
      "           2       0.77      0.62      0.69       100\n",
      "           3       0.95      0.94      0.94       100\n",
      "           4       0.93      0.92      0.92       100\n",
      "           5       0.79      0.95      0.86       100\n",
      "           6       0.78      0.82      0.80       100\n",
      "           7       0.92      0.98      0.95        88\n",
      "           8       0.89      0.94      0.91        99\n",
      "           9       0.93      0.83      0.88       100\n",
      "          10       0.92      0.90      0.91       100\n",
      "          11       0.96      0.84      0.90        97\n",
      "          12       0.98      0.97      0.97       100\n",
      "          13       0.96      0.98      0.97       100\n",
      "          14       0.95      0.98      0.97       100\n",
      "          15       1.00      0.97      0.98       100\n",
      "          16       0.93      0.98      0.96       100\n",
      "          17       0.99      0.97      0.98       100\n",
      "          18       0.98      0.98      0.98        99\n",
      "          19       1.00      0.98      0.99       100\n",
      "          20       0.90      0.88      0.89       100\n",
      "          21       0.96      0.91      0.93       100\n",
      "          22       1.00      0.97      0.98       100\n",
      "          23       0.94      0.94      0.94       100\n",
      "          24       0.93      0.96      0.95       100\n",
      "          25       0.99      0.97      0.98       100\n",
      "          26       0.78      0.76      0.77       100\n",
      "          27       0.89      0.89      0.89       100\n",
      "          28       0.97      0.97      0.97       100\n",
      "          29       0.95      0.99      0.97       100\n",
      "          30       0.94      1.00      0.97        99\n",
      "          31       0.96      0.98      0.97       100\n",
      "          32       0.92      0.94      0.93       100\n",
      "          33       0.95      0.99      0.97       100\n",
      "          34       0.69      0.70      0.69        89\n",
      "          35       0.98      0.95      0.96       100\n",
      "          36       0.99      0.96      0.97       100\n",
      "\n",
      "    accuracy                           0.92      3669\n",
      "   macro avg       0.92      0.92      0.92      3669\n",
      "weighted avg       0.92      0.92      0.92      3669\n",
      "\n",
      "\n",
      "Performance Comparison Summary:\n",
      "--------------------------------------------------\n",
      "Pre-trained Model Accuracy: 0.0292\n",
      "Fine-tuned Model Accuracy: 0.9220\n",
      "Absolute Improvement: 0.8929\n",
      "Relative Improvement: 3061.68%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Cargar y preparar el dataset\n",
    "data_dir = './data'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Cargar los datasets\n",
    "train_dataset = OxfordIIITPet(root=data_dir, split='trainval', target_types='category', \n",
    "                             download=True, transform=transform)\n",
    "test_dataset = OxfordIIITPet(root=data_dir, split='test', target_types='category', \n",
    "                            download=True, transform=transform)\n",
    "\n",
    "# Crear los Dataloaders para el procesamiento en baches\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 2. Cargar el modelo pre entrenado\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "pretrained_model = ViTForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "# Crear una copia para el fine tuning\n",
    "model = copy.deepcopy(pretrained_model)\n",
    "\n",
    "# 3. Modificar ambos modelos para clasificacion de mascotas\n",
    "num_labels = 37\n",
    "for m in [pretrained_model, model]:\n",
    "    m.classifier = torch.nn.Linear(m.config.hidden_size, num_labels)\n",
    "    m.num_labels = num_labels\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrained_model.to(device)\n",
    "model.to(device)\n",
    "\n",
    "# 4. Evaluar el modelo pre entrenado\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    return accuracy, report\n",
    "\n",
    "print(\"Evaluating pre-trained model (before fine-tuning)...\")\n",
    "pretrained_accuracy, pretrained_report = evaluate_model(pretrained_model, test_loader, device)\n",
    "print(f\"Pre-trained Model Accuracy: {pretrained_accuracy:.4f}\")\n",
    "print(\"\\nDetailed Classification Report (Pre-trained):\")\n",
    "print(pretrained_report)\n",
    "\n",
    "# 5. Fine tuning del modelo\n",
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 10\n",
    "\n",
    "# Lists para guardar las métricas\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "print(\"\\nStarting fine-tuning process...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    \n",
    "    # Loop de training\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_losses.append(loss.item())\n",
    "    \n",
    "    # Calcualr el promedio de la pérdida para esta epoca\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    # Evaluar el modelo en el set de test\n",
    "    test_accuracy, _ = evaluate_model(model, test_loader, device)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Average Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 6. Evaluacion final del modelo con fine tuning\n",
    "print(\"\\nEvaluating fine-tuned model...\")\n",
    "finetuned_accuracy, finetuned_report = evaluate_model(model, test_loader, device)\n",
    "print(f\"Fine-tuned Model Accuracy: {finetuned_accuracy:.4f}\")\n",
    "print(\"\\nDetailed Classification Report (Fine-tuned):\")\n",
    "print(finetuned_report)\n",
    "\n",
    "# 7. Imprimir las comparaciones\n",
    "print(\"\\nPerformance Comparison Summary:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Pre-trained Model Accuracy: {pretrained_accuracy:.4f}\")\n",
    "print(f\"Fine-tuned Model Accuracy: {finetuned_accuracy:.4f}\")\n",
    "print(f\"Absolute Improvement: {(finetuned_accuracy - pretrained_accuracy):.4f}\")\n",
    "print(f\"Relative Improvement: {((finetuned_accuracy - pretrained_accuracy) / pretrained_accuracy * 100):.2f}%\")\n",
    "\n",
    "# Guardar el modelo con fine tuning\n",
    "model.save_pretrained(\"./pet_classifier_finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Una vez finalizado el fine-tuning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Justifique la elección del modelo preentrenado y del dataset.**\n",
    " - Este modelo google/vit-base-patch16-224 procesa imagenes en parches de 16*16. Lo cual es efectivo para detectar características en mascotas como patrones de pelo y estructura del cuerpo.\n",
    " - Las imágenes pre entrenadas con ImageNet-21k, las cuales incluyen varias categorías de animales, proveen extracción de caracteristicas relevantes.\n",
    " - La resolución de 224*224 se ajusta a las escalas comunes de fotografías.\n",
    "\n",
    " El dataset Oxford-IIIT Pet.\n",
    " - Cuenta 7349 imágenes y 37 categorías de mascotas (25 razas de perros, y 12 de gatos)\n",
    " - Inlcuye división de entrenamiento y test, para hacer una buena evaluación.\n",
    " - Tiene una buena variabilidad de imágenes. Con diferentes posiciones, iluminanción y fondos.\n",
    " - La clasificación es bien detallada. Lo cual ayuda a detectar pequeñas diferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Explique el proceso de fine-tuning realizado, especificando los parámetros ajustados y las modificaciones necesarias.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de optimización\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Modificaciones al modelo\n",
    "num_labels = 37\n",
    "model.classifier = torch.nn.Linear(model.config.hidden_size, num_labels)\n",
    "model.num_labels = num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificaciones implementadas.\n",
    "- Procesamiento de datos.\n",
    "Procesamiento de a 32 imagenes por batch. Para un entrenamiento estable.\n",
    "Resize de los transforms a 224*224 para que sean compatibles con los requerimeintos de entrada del ViT.\n",
    "Dataloader con datos de entrenamiento aleatorios\n",
    "\n",
    "- Arquitectura del modelo\n",
    "Se reemplazó la cabeza de clasificación, preservando la estructura pre entrenada\n",
    "Se modificó la dimensión de salida para las 37 clases de mascotas\n",
    "\n",
    "- Estrategia de entrenamiento\n",
    "Se usó un learning rate bajo. Esto para prevenir olvidos\n",
    "Se usó el optimizador AdamW, con caida de pesos para regularización\n",
    "Se usaron 10 epocas para el entrenamiento, con evaluación completa luego de cada epoca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evalúe el rendimiento del modelo preentrenado sin ajustes y compárelo con los resultados obtenidos tras el fine-tuning, discutiendo las mejoras o diferencias observadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo pre entrenado. Antes del fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre-trained Model Accuracy: 0.0271  # Valor de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El desempeño del modelo es aleatorio en la clasificación de mascotas.\n",
    "Baja diferenciación entre razas similares\n",
    "Alta confusión entre razas de gatos y perros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego del fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fine-tuned Model Accuracy: 0.8943  # Valor de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mejoras cuantitativas\n",
    "Incremento de la accuracy del 2.7 al 89.4%\n",
    "Una mejora del 3200%\n",
    "Desempeño mas balanceado entre las 37 clases\n",
    "\n",
    "- Mejoras cualitativas\n",
    "Un aprendizaje exitoso en cuanto a características específicas de las razas\n",
    "Mejor discriminacion entre razas parecidas\n",
    "Menor confusión entre gatos y perros\n",
    "\n",
    "- Mejoras en el comportamiento del modelo\n",
    "Predicciones mas confiables en muestras de test\n",
    "Mejor generalización a diferentes posiciones y condiciones de iluminación\n",
    "Una extracción de características mas robusta. Enfocada en características relevantes de mascotas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
